{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMw8qabGgQ5/Pm6jI5ILxcs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhanush852/intro_to-ml/blob/main/Homework5_1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmDmxxOctVh-",
        "outputId": "d136e37a-6063-4e86-cb56-479e7b5180f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.2-py2.py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->ipython-autotime)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.13)\n",
            "Installing collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.2 jedi-0.19.1\n",
            "time: 374 µs (started: 2024-04-27 20:24:14 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyCmkVUhtaNV",
        "outputId": "c9a027cd-98ff-468c-f10e-6f6f1553d8da"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.48 s (started: 2024-04-27 20:24:14 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text = '''Next character prediction is a fundamental task in the field of natural language processing (NLP) that involves predicting the next character in a sequence of text based on the characters that precede it. This task is essential for various applications, including text auto-completion, spell checking, and even in the development of sophisticated AI models capable of generating human-like text.\n",
        "\n",
        "At its core, next character prediction relies on statistical models or deep learning algorithms to analyze a given sequence of text and predict which character is most likely to follow. These predictions are based on patterns and relationships learned from large datasets of text during the training phase of the model.\n",
        "\n",
        "One of the most popular approaches to next character prediction involves the use of Recurrent Neural Networks (RNNs), and more specifically, a variant called Long Short-Term Memory (LSTM) networks. RNNs are particularly well-suited for sequential data like text, as they can maintain information in 'memory' about previous characters to inform the prediction of the next character. LSTM networks enhance this capability by being able to remember long-term dependencies, making them even more effective for next character prediction tasks.\n",
        "\n",
        "Training a model for next character prediction involves feeding it large amounts of text data, allowing it to learn the probability of each character's appearance following a sequence of characters. During this training process, the model adjusts its parameters to minimize the difference between its predictions and the actual outcomes, thus improving its predictive accuracy over time.\n",
        "\n",
        "Once trained, the model can be used to predict the next character in a given piece of text by considering the sequence of characters that precede it. This can enhance user experience in text editing software, improve efficiency in coding environments with auto-completion features, and enable more natural interactions with AI-based chatbots and virtual assistants.\n",
        "\n",
        "In summary, next character prediction plays a crucial role in enhancing the capabilities of various NLP applications, making text-based interactions more efficient, accurate, and human-like. Through the use of advanced machine learning models like RNNs and LSTMs, next character prediction continues to evolve, opening new possibilities for the future of text-based technology.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGNCe38jtcNq",
        "outputId": "cccc6704-dd7e-41f8-bb43-8a40713ace46"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5.51 ms (started: 2024-04-27 20:24:18 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the maximum length for each input sequence\n",
        "max_length = 10\n",
        "sequences = [text[start_idx:start_idx + max_length] for start_idx in range(len(text) - max_length)]\n",
        "labels = [text[start_idx + max_length] for start_idx in range(len(text) - max_length)]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tibLXJWZtirP",
        "outputId": "4329ccdb-e6c1-41bd-d0d2-7997f03ca4c8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 8.63 ms (started: 2024-04-27 20:24:18 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating character vocabulary\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_ix = {ch: i for i, ch in enumerate(chars)}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rG1aC5hqNKfg",
        "outputId": "00ca11a7-a44a-408b-c90a-80fbc413366f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 571 µs (started: 2024-04-27 20:24:18 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([[char_to_ix[ch] for ch in seq] for seq in sequences], dtype = torch.long)\n",
        "\n",
        "y = torch.tensor([char_to_ix[label] for label in labels], dtype = torch.long)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmsTaDTCxOgk",
        "outputId": "6eef7e38-936b-4ecb-b063-682bc9ec2e58"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 35.9 ms (started: 2024-04-27 20:24:18 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating character vocabulary\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_ix = {ch: i for i, ch in enumerate(chars)}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz9mvr0fxZGJ",
        "outputId": "38e9d04b-8868-4cb4-afff-7cc47605d62c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 550 µs (started: 2024-04-27 20:24:18 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJEk_ixyPJJU",
        "outputId": "1389528c-534c-4156-c333-4551c324f562"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 42.1 ms (started: 2024-04-27 20:26:13 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class CharTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_dim, num_classes, num_layers, num_heads):\n",
        "        super(CharTransformer, self).__init__()\n",
        "        # Embedding layer to convert input indices to vectors\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
        "        # Encoder layer for the transformer\n",
        "        encoder_layer = nn.TransformerEncoderLayer(hidden_dim, num_heads)\n",
        "        # Transformer encoder\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
        "        # Fully connected layer to map transformer outputs to class scores\n",
        "        self.fc_out = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, input_indices):\n",
        "        # Convert indices to embeddings\n",
        "        embeddings = self.embedding(input_indices)\n",
        "        # Pass embeddings through the transformer encoder\n",
        "        transformer_out = self.transformer_encoder(embeddings)\n",
        "        # Output the transformed last token for prediction\n",
        "        final_output = self.fc_out(transformer_out[:, -1, :])\n",
        "        return final_output\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaDq3IGyNdQD",
        "outputId": "694ce0aa-49e9-4469-90ed-86cacc456f80"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 737 µs (started: 2024-04-27 20:26:15 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_dim = 128\n",
        "num_layers = 3       # Number of layers in the model\n",
        "num_heads = 2        # Number of attention heads in the transformer model\n",
        "learning_rate = 0.01  # Learning rate for training the model\n",
        "epoch_count = 100     # Total number of training epochs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kmsk7l8WNxl1",
        "outputId": "27903bb1-46a3-41f2-80ec-9f88fb200628"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 813 µs (started: 2024-04-27 20:39:58 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBHyeldcObgR",
        "outputId": "5ddd0895-49cc-4ab1-c981-cbe321bad387"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 527 µs (started: 2024-04-27 20:40:00 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Moving training and validation data to the specified device (e.g., GPU or CPU)\n",
        "datasets = (X_train, y_train, X_val, y_val) = [tensor.to(device) for tensor in (X_train, y_train, X_val, y_val)]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qeaRHHQO95x",
        "outputId": "10641569-094b-4698-fedb-2022e2720fca"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 890 µs (started: 2024-04-27 20:40:01 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "model = CharTransformer(len(chars),  hidden_dim, len(chars), num_layers, num_heads)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtvSyFKQO2Jk",
        "outputId": "001ee4dd-03aa-467b-ece1-9ccedf3316d5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.07 s (started: 2024-04-27 20:40:20 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):  # Train for 100 epochs\n",
        "    model.train()  # Set the model to training mode\n",
        "    optimizer.zero_grad()  # Clear gradients before each step\n",
        "\n",
        "    train_output = model(X_train)\n",
        "    train_loss = criterion(train_output, y_train)\n",
        "    train_loss.backward()  # Backpropagation\n",
        "    optimizer.step()  # Update model parameters\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
        "        val_output = model(X_val)  # Forward pass with validation data\n",
        "        val_loss = criterion(val_output, y_val)  # Calculate loss\n",
        "        _, predictions = torch.max(val_output, 1)  # Predictions\n",
        "        val_accuracy = (predictions == y_val).float().mean()  # Calculate accuracy\n",
        "\n",
        "    # Log performance every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch {epoch + 1}, Train Loss: {train_loss.item()}, Validation Loss: {val_loss.item()}, Validation Accuracy: {val_accuracy.item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyUCoor7QHyp",
        "outputId": "c3dd3e1d-ae03-4b5a-9ce6-2c441cdc10f4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Train Loss: 3.0886178016662598, Validation Loss: 3.038475275039673, Validation Accuracy: 0.1446540802717209\n",
            "Epoch 20, Train Loss: 3.0617117881774902, Validation Loss: 3.0223729610443115, Validation Accuracy: 0.1446540802717209\n",
            "Epoch 30, Train Loss: 3.052079916000366, Validation Loss: 3.0179507732391357, Validation Accuracy: 0.1446540802717209\n",
            "Epoch 40, Train Loss: 3.0544931888580322, Validation Loss: 3.01273250579834, Validation Accuracy: 0.1446540802717209\n",
            "Epoch 50, Train Loss: 3.0529589653015137, Validation Loss: 3.013514518737793, Validation Accuracy: 0.1446540802717209\n",
            "Epoch 60, Train Loss: 3.0458195209503174, Validation Loss: 3.013235569000244, Validation Accuracy: 0.1446540802717209\n",
            "Epoch 70, Train Loss: 3.0453591346740723, Validation Loss: 3.0126118659973145, Validation Accuracy: 0.1446540802717209\n",
            "Epoch 80, Train Loss: 3.0419070720672607, Validation Loss: 3.01328182220459, Validation Accuracy: 0.1446540802717209\n",
            "Epoch 90, Train Loss: 3.0490903854370117, Validation Loss: 3.012441635131836, Validation Accuracy: 0.1446540802717209\n",
            "Epoch 100, Train Loss: 3.0415761470794678, Validation Loss: 3.0123817920684814, Validation Accuracy: 0.1446540802717209\n",
            "time: 21.3 s (started: 2024-04-27 20:43:02 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "import torchinfo\n",
        "torchinfo.summary(model, input_data=X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk3UQUN-TAj8",
        "outputId": "5dde6109-2c17-46cc-cbb3-b362c9441a27"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "CharTransformer                               [1904, 45]                --\n",
              "├─Embedding: 1-1                              [1904, 10, 128]           5,760\n",
              "├─TransformerEncoder: 1-2                     [1904, 10, 128]           --\n",
              "│    └─ModuleList: 2-1                        --                        --\n",
              "│    │    └─TransformerEncoderLayer: 3-1      [1904, 10, 128]           593,024\n",
              "│    │    └─TransformerEncoderLayer: 3-2      [1904, 10, 128]           593,024\n",
              "│    │    └─TransformerEncoderLayer: 3-3      [1904, 10, 128]           593,024\n",
              "├─Linear: 1-3                                 [1904, 45]                5,805\n",
              "===============================================================================================\n",
              "Total params: 1,790,637\n",
              "Trainable params: 1,790,637\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 3.03\n",
              "===============================================================================================\n",
              "Input size (MB): 0.15\n",
              "Forward/backward pass size (MB): 1131.51\n",
              "Params size (MB): 6.37\n",
              "Estimated Total Size (MB): 1138.03\n",
              "==============================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5.44 s (started: 2024-04-27 20:44:17 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sequence =**20**"
      ],
      "metadata": {
        "id": "Z67Tdp5bTpoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 20\n",
        "\n",
        "# Extract sequences and corresponding labels from the text\n",
        "sequences = [text[i:i + max_length] for i in range(len(text) - max_length)]\n",
        "labels = [text[i + max_length] for i in range(len(text) - max_length)]\n",
        "\n",
        "# Generate a unique set of characters and map each character to an index\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_ix = {ch: i for i, ch in enumerate(chars)}\n",
        "\n",
        "# Convert sequences and labels into tensors of indices\n",
        "X = torch.tensor([[char_to_ix[ch] for ch in seq] for seq in sequences], dtype=torch.long)\n",
        "y = torch.tensor([char_to_ix[label] for label in labels], dtype=torch.long)\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=100)\n",
        "\n",
        "# Move tensors to the specified device\n",
        "X_train = X_train.to(device)\n",
        "y_train = y_train.to(device)\n",
        "X_val = X_val.to(device)\n",
        "y_val = y_val.to(device)\n",
        "\n",
        "# Initialize the CharTransformer model with predefined settings\n",
        "model = CharTransformer(len(chars),  hidden_dim, len(chars), num_layers, num_heads)\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xd17n4AbTpTd",
        "outputId": "c8964950-74be-4cf5-c7e2-c332d19b5732"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 38.3 ms (started: 2024-04-27 20:48:16 +00:00)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    train_output = model(X_train)\n",
        "    train_loss = criterion(train_output, y_train)\n",
        "    train_loss.backward()  # Backpropagation\n",
        "    optimizer.step()  # Update model parameters\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
        "        val_output = model(X_val)  # Forward pass with validation data\n",
        "        val_loss = criterion(val_output, y_val)  # Calculate loss\n",
        "        _, predictions = torch.max(val_output, 1)  # Predictions\n",
        "        val_accuracy = (predictions == y_val).float().mean()  # Calculate accuracy\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch {epoch + 1}, Train Loss: {train_loss.item()}, Validation Loss: {val_loss.item()}, Validation Accuracy: {val_accuracy.item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odoFkIO3TSt6",
        "outputId": "2b24fe71-6396-438c-aa0c-7feb293be491"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Train Loss: 3.086601495742798, Validation Loss: 3.0331029891967773, Validation Accuracy: 0.14526315033435822\n",
            "Epoch 20, Train Loss: 3.0611352920532227, Validation Loss: 3.0283470153808594, Validation Accuracy: 0.14526315033435822\n",
            "Epoch 30, Train Loss: 3.0613150596618652, Validation Loss: 3.025937080383301, Validation Accuracy: 0.14526315033435822\n",
            "Epoch 40, Train Loss: 3.0593910217285156, Validation Loss: 3.0231242179870605, Validation Accuracy: 0.14526315033435822\n",
            "Epoch 50, Train Loss: 3.057526111602783, Validation Loss: 3.022125244140625, Validation Accuracy: 0.14526315033435822\n",
            "Epoch 60, Train Loss: 3.05175518989563, Validation Loss: 3.023834705352783, Validation Accuracy: 0.14526315033435822\n",
            "Epoch 70, Train Loss: 3.0567452907562256, Validation Loss: 3.024379253387451, Validation Accuracy: 0.14526315033435822\n",
            "Epoch 80, Train Loss: 3.050891637802124, Validation Loss: 3.023371934890747, Validation Accuracy: 0.14526315033435822\n",
            "Epoch 90, Train Loss: 3.0479085445404053, Validation Loss: 3.023089647293091, Validation Accuracy: 0.14526315033435822\n",
            "Epoch 100, Train Loss: 3.048264503479004, Validation Loss: 3.023447036743164, Validation Accuracy: 0.14526315033435822\n",
            "time: 37.6 s (started: 2024-04-27 20:51:34 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torchinfo.summary(model, input_data = X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKGlS5u0U714",
        "outputId": "437906a7-4e50-4e21-d02b-f95154dbea4c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "CharTransformer                               [1896, 45]                --\n",
              "├─Embedding: 1-1                              [1896, 20, 128]           5,760\n",
              "├─TransformerEncoder: 1-2                     [1896, 20, 128]           --\n",
              "│    └─ModuleList: 2-1                        --                        --\n",
              "│    │    └─TransformerEncoderLayer: 3-1      [1896, 20, 128]           593,024\n",
              "│    │    └─TransformerEncoderLayer: 3-2      [1896, 20, 128]           593,024\n",
              "│    │    └─TransformerEncoderLayer: 3-3      [1896, 20, 128]           593,024\n",
              "├─Linear: 1-3                                 [1896, 45]                5,805\n",
              "===============================================================================================\n",
              "Total params: 1,790,637\n",
              "Trainable params: 1,790,637\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 3.02\n",
              "===============================================================================================\n",
              "Input size (MB): 0.30\n",
              "Forward/backward pass size (MB): 2252.83\n",
              "Params size (MB): 6.37\n",
              "Estimated Total Size (MB): 2259.50\n",
              "==============================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 13.2 ms (started: 2024-04-27 20:52:14 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sequence = 30"
      ],
      "metadata": {
        "id": "GWQpH9MkVcM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 30\n",
        "\n",
        "\n",
        "sequences = [text[i:i + max_length] for i in range(len(text) - max_length)]\n",
        "labels = [text[i + max_length] for i in range(len(text) - max_length)]\n",
        "\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_ix = {ch: i for i, ch in enumerate(chars)}\n",
        "\n",
        "\n",
        "X = torch.tensor([[char_to_ix[ch] for ch in seq] for seq in sequences], dtype=torch.long)\n",
        "y = torch.tensor([char_to_ix[label] for label in labels], dtype=torch.long)\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=100)\n",
        "\n",
        "X_train = X_train.to(device)\n",
        "y_train = y_train.to(device)\n",
        "X_val = X_val.to(device)\n",
        "y_val = y_val.to(device)\n",
        "\n",
        "# Initialize the CharTransformer model with the specified configuration\n",
        "model = CharTransformer(len(chars),  hidden_dim, len(chars), num_layers, num_heads)\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcreR3X3VHIF",
        "outputId": "eadf3905-7434-414f-afbf-b6b4a4c4654b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 178 ms (started: 2024-04-27 20:54:38 +00:00)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "    model.train()  # Set the model to training mode\n",
        "    optimizer.zero_grad()  # Clear gradients before each step\n",
        "\n",
        "    train_output = model(X_train)\n",
        "    train_loss = criterion(train_output, y_train)\n",
        "    train_loss.backward()  # Backpropagation\n",
        "    optimizer.step()  # Update model parameters\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
        "        val_output = model(X_val)  # Forward pass with validation data\n",
        "        val_loss = criterion(val_output, y_val)  # Calculate loss\n",
        "        _, predictions = torch.max(val_output, 1)  # Get predictions from the max logit\n",
        "        val_accuracy = (predictions == y_val).float().mean()  # Calculate accuracy\n",
        "\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch {epoch + 1}, Train Loss: {train_loss.item()}, Validation Loss: {val_loss.item()}, Validation Accuracy: {val_accuracy.item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cx5ItUsZVfmy",
        "outputId": "1d196edd-c7a5-4f1f-a470-cb775800b2df"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Train Loss: 3.06044602394104, Validation Loss: 3.1337132453918457, Validation Accuracy: 0.12896405160427094\n",
            "Epoch 20, Train Loss: 3.0313990116119385, Validation Loss: 3.1407930850982666, Validation Accuracy: 0.12896405160427094\n",
            "Epoch 30, Train Loss: 3.0332605838775635, Validation Loss: 3.1422150135040283, Validation Accuracy: 0.12896405160427094\n",
            "Epoch 40, Train Loss: 3.0287342071533203, Validation Loss: 3.1328587532043457, Validation Accuracy: 0.12896405160427094\n",
            "Epoch 50, Train Loss: 3.023965835571289, Validation Loss: 3.136594295501709, Validation Accuracy: 0.12896405160427094\n",
            "Epoch 60, Train Loss: 3.0283520221710205, Validation Loss: 3.136806011199951, Validation Accuracy: 0.12896405160427094\n",
            "Epoch 70, Train Loss: 3.0271029472351074, Validation Loss: 3.1333842277526855, Validation Accuracy: 0.12896405160427094\n",
            "Epoch 80, Train Loss: 3.0184733867645264, Validation Loss: 3.1359405517578125, Validation Accuracy: 0.12896405160427094\n",
            "Epoch 90, Train Loss: 3.020108699798584, Validation Loss: 3.1356334686279297, Validation Accuracy: 0.12896405160427094\n",
            "Epoch 100, Train Loss: 3.019237518310547, Validation Loss: 3.134320020675659, Validation Accuracy: 0.12896405160427094\n",
            "time: 56.3 s (started: 2024-04-27 20:56:05 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torchinfo.summary(model, input_data = X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUllSSc6V_pq",
        "outputId": "b420e6e1-35f0-491d-be6f-601184716998"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "CharTransformer                               [1888, 45]                --\n",
              "├─Embedding: 1-1                              [1888, 30, 128]           5,760\n",
              "├─TransformerEncoder: 1-2                     [1888, 30, 128]           --\n",
              "│    └─ModuleList: 2-1                        --                        --\n",
              "│    │    └─TransformerEncoderLayer: 3-1      [1888, 30, 128]           593,024\n",
              "│    │    └─TransformerEncoderLayer: 3-2      [1888, 30, 128]           593,024\n",
              "│    │    └─TransformerEncoderLayer: 3-3      [1888, 30, 128]           593,024\n",
              "├─Linear: 1-3                                 [1888, 45]                5,805\n",
              "===============================================================================================\n",
              "Total params: 1,790,637\n",
              "Trainable params: 1,790,637\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 3.01\n",
              "===============================================================================================\n",
              "Input size (MB): 0.45\n",
              "Forward/backward pass size (MB): 3364.64\n",
              "Params size (MB): 6.37\n",
              "Estimated Total Size (MB): 3371.47\n",
              "==============================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 12.6 ms (started: 2024-04-27 20:57:01 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "question 2 (1)"
      ],
      "metadata": {
        "id": "wYHO7biEWt0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "response = requests.get(url)\n",
        "text = response.text\n",
        "\n",
        "\n",
        "sequence_length = 20\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_int = {ch: i for i, ch in enumerate(chars)}\n",
        "int_to_char = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "encoded_text = [char_to_int[ch] for ch in text]\n",
        "\n",
        "\n",
        "sequences = [encoded_text[i:i + sequence_length] for i in range(len(encoded_text) - sequence_length)]\n",
        "targets = [encoded_text[i + sequence_length] for i in range(len(encoded_text) - sequence_length)]\n",
        "\n",
        "sequences_tensor = torch.tensor(sequences, dtype=torch.long)\n",
        "targets_tensor = torch.tensor(targets, dtype=torch.long)\n",
        "\n",
        "class CharDataset(Dataset):\n",
        "    def __init__(self, sequences, targets):\n",
        "        self.sequences = sequences\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.sequences[index], self.targets[index]\n",
        "\n",
        "dataset = CharDataset(sequences_tensor, targets_tensor)\n",
        "\n",
        "batch_size = 128\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuWP62F0W6NL",
        "outputId": "67b88918-69f4-4874-b2a0-b6ff9ea100b4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5 s (started: 2024-04-27 21:05:13 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class CharTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, num_classes, layers_count, heads_count):\n",
        "        super(CharTransformer, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=emb_dim, nhead=heads_count)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=layers_count)\n",
        "        self.output_layer = nn.Linear(emb_dim, num_classes)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeddings = self.embedding(inputs)\n",
        "        encoder_outputs = self.transformer_encoder(embeddings)\n",
        "        final_output = self.output_layer(encoder_outputs[:, -1])\n",
        "        return final_output\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkLQACSCXsyS",
        "outputId": "2386a19f-f619-46b6-9743-3d62c30afe6a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.12 ms (started: 2024-04-27 21:08:31 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 512\n",
        "num_layers = 2\n",
        "num_heads = 2\n",
        "learning_rate = 0.001\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "epochs = 15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHcSBK2HY1pt",
        "outputId": "09545160-446b-4fb0-9516-1da910866ea6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 883 µs (started: 2024-04-27 21:08:45 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "# Instantiate the model with specific configurations and send to compute device\n",
        "model = CharTransformer(vocab_size=len(chars), emb_dim=128, num_classes=len(chars),\n",
        "                        layers_count=3, heads_count=2).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training and validation loop\n",
        "for epoch in range(10):\n",
        "    model.train()  # Set model to training mode\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Training phase\n",
        "    for batch_inputs, batch_targets in train_loader:\n",
        "        batch_inputs, batch_targets = batch_inputs.to(device), batch_targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        train_outputs = model(batch_inputs)\n",
        "        train_loss = criterion(train_outputs, batch_targets)\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "        total_train_loss += train_loss.item() * batch_inputs.size(0)\n",
        "\n",
        "    average_train_loss = total_train_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    total_val_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_inputs, batch_targets in test_loader:\n",
        "            batch_inputs, batch_targets = batch_inputs.to(device), batch_targets.to(device)\n",
        "            val_outputs = model(batch_inputs)\n",
        "            val_loss = criterion(val_outputs, batch_targets)\n",
        "            total_val_loss += val_loss.item() * batch_inputs.size(0)\n",
        "            _, predictions = torch.max(val_outputs, 1)\n",
        "            total_predictions += batch_targets.size(0)\n",
        "            correct_predictions += (predictions == batch_targets).sum().item()\n",
        "\n",
        "    average_val_loss = total_val_loss / len(test_loader.dataset)\n",
        "    validation_accuracy = correct_predictions / total_predictions\n",
        "\n",
        "    # Output training and validation results\n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        print(f'Epoch {epoch + 1}, Train Loss: {average_train_loss:.4f}, '\n",
        "              f'Validation Loss: {average_val_loss:.4f}, Validation Accuracy: {validation_accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2lLIIIYZTVd",
        "outputId": "a0b01dd4-58cb-43b8-9149-46f9855d51ae"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Train Loss: 3.3241, Validation Loss: 3.3182, Validation Accuracy: 0.1525\n",
            "Epoch 2, Train Loss: 3.3186, Validation Loss: 3.3204, Validation Accuracy: 0.1525\n",
            "Epoch 3, Train Loss: 3.3182, Validation Loss: 3.3193, Validation Accuracy: 0.1525\n",
            "Epoch 4, Train Loss: 3.3181, Validation Loss: 3.3189, Validation Accuracy: 0.1525\n",
            "Epoch 5, Train Loss: 3.3181, Validation Loss: 3.3185, Validation Accuracy: 0.1525\n",
            "Epoch 6, Train Loss: 3.3182, Validation Loss: 3.3148, Validation Accuracy: 0.1525\n",
            "Epoch 7, Train Loss: 3.3184, Validation Loss: 3.3204, Validation Accuracy: 0.1525\n",
            "Epoch 8, Train Loss: 3.3184, Validation Loss: 3.3164, Validation Accuracy: 0.1525\n",
            "Epoch 9, Train Loss: 3.3184, Validation Loss: 3.3188, Validation Accuracy: 0.1525\n",
            "Epoch 10, Train Loss: 3.3183, Validation Loss: 3.3163, Validation Accuracy: 0.1525\n",
            "time: 17min 40s (started: 2024-04-27 21:49:59 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "import torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUC_Dl4mZsxa",
        "outputId": "3a5fdf84-794f-43bb-ac81-a7b0a5992a2e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "time: 5.12 s (started: 2024-04-27 22:07:39 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataiter = iter(train_loader)\n",
        "inputs, labels = next(dataiter)  # Get one batch of data\n",
        "\n",
        "model.to(inputs.device)\n",
        "summary = torchinfo.summary(model, input_data=(inputs,))\n",
        "print(summary)\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BC3v_cYWZ9kJ",
        "outputId": "902da854-b13b-4dad-e72f-16e618f4ebcf"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===============================================================================================\n",
            "Layer (type:depth-idx)                        Output Shape              Param #\n",
            "===============================================================================================\n",
            "CharTransformer                               [128, 65]                 --\n",
            "├─Embedding: 1-1                              [128, 20, 128]            8,320\n",
            "├─TransformerEncoder: 1-2                     [128, 20, 128]            --\n",
            "│    └─ModuleList: 2-1                        --                        --\n",
            "│    │    └─TransformerEncoderLayer: 3-1      [128, 20, 128]            593,024\n",
            "│    │    └─TransformerEncoderLayer: 3-2      [128, 20, 128]            593,024\n",
            "│    │    └─TransformerEncoderLayer: 3-3      [128, 20, 128]            593,024\n",
            "├─Linear: 1-3                                 [128, 65]                 8,385\n",
            "===============================================================================================\n",
            "Total params: 1,795,777\n",
            "Trainable params: 1,795,777\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 204.50\n",
            "===============================================================================================\n",
            "Input size (MB): 0.02\n",
            "Forward/backward pass size (MB): 152.11\n",
            "Params size (MB): 6.39\n",
            "Estimated Total Size (MB): 158.52\n",
            "===============================================================================================\n",
            "time: 360 ms (started: 2024-04-27 22:07:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequence = 30"
      ],
      "metadata": {
        "id": "KZu5-bF7jFM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "response = requests.get(url)\n",
        "text = response.text\n",
        "\n",
        "\n",
        "sequence_length = 30\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_int = {ch: i for i, ch in enumerate(chars)}\n",
        "int_to_char = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "encoded_text = [char_to_int[ch] for ch in text]\n",
        "\n",
        "\n",
        "sequences = [encoded_text[i:i + sequence_length] for i in range(len(encoded_text) - sequence_length)]\n",
        "targets = [encoded_text[i + sequence_length] for i in range(len(encoded_text) - sequence_length)]\n",
        "\n",
        "sequences_tensor = torch.tensor(sequences, dtype=torch.long)\n",
        "targets_tensor = torch.tensor(targets, dtype=torch.long)\n",
        "\n",
        "class CharDataset(Dataset):\n",
        "    def __init__(self, sequences, targets):\n",
        "        self.sequences = sequences\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.sequences[index], self.targets[index]\n",
        "\n",
        "dataset = CharDataset(sequences_tensor, targets_tensor)\n",
        "\n",
        "batch_size = 128\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS6bghiJjD_U",
        "outputId": "aef1ea79-9895-4d44-cb55-ee267dd2497a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 6.31 s (started: 2024-04-27 22:07:45 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class CharTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, num_classes, layers_count, heads_count):\n",
        "        super(CharTransformer, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=emb_dim, nhead=heads_count)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=layers_count)\n",
        "        self.output_layer = nn.Linear(emb_dim, num_classes)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeddings = self.embedding(inputs)\n",
        "        encoder_outputs = self.transformer_encoder(embeddings)\n",
        "        final_output = self.output_layer(encoder_outputs[:, -1])\n",
        "        return final_output\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBLr1c0bjOPI",
        "outputId": "c6990b34-5dbf-40f9-f83c-cc7d3b5a0ad1"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 699 µs (started: 2024-04-27 22:07:39 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 512\n",
        "num_layers = 2\n",
        "num_heads = 2\n",
        "learning_rate = 0.001\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "epochs = 15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAjegzlejUZO",
        "outputId": "686e2826-6998-4360-9d7c-6149449630d7"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 754 µs (started: 2024-04-27 22:07:51 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "# Instantiate the model with specific configurations and send to compute device\n",
        "model = CharTransformer(vocab_size=len(chars), emb_dim=128, num_classes=len(chars),\n",
        "                        layers_count=3, heads_count=2).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training and validation loop\n",
        "for epoch in range(10):\n",
        "    model.train()  # Set model to training mode\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Training phase\n",
        "    for batch_inputs, batch_targets in train_loader:\n",
        "        batch_inputs, batch_targets = batch_inputs.to(device), batch_targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        train_outputs = model(batch_inputs)\n",
        "        train_loss = criterion(train_outputs, batch_targets)\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "        total_train_loss += train_loss.item() * batch_inputs.size(0)\n",
        "\n",
        "    average_train_loss = total_train_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    total_val_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_inputs, batch_targets in test_loader:\n",
        "            batch_inputs, batch_targets = batch_inputs.to(device), batch_targets.to(device)\n",
        "            val_outputs = model(batch_inputs)\n",
        "            val_loss = criterion(val_outputs, batch_targets)\n",
        "            total_val_loss += val_loss.item() * batch_inputs.size(0)\n",
        "            _, predictions = torch.max(val_outputs, 1)\n",
        "            total_predictions += batch_targets.size(0)\n",
        "            correct_predictions += (predictions == batch_targets).sum().item()\n",
        "\n",
        "    average_val_loss = total_val_loss / len(test_loader.dataset)\n",
        "    validation_accuracy = correct_predictions / total_predictions\n",
        "\n",
        "    # Output training and validation results\n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        print(f'Epoch {epoch + 1}, Train Loss: {average_train_loss:.4f}, '\n",
        "              f'Validation Loss: {average_val_loss:.4f}, Validation Accuracy: {validation_accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jOikogMjdiC",
        "outputId": "6da1a036-86bb-4e78-db4d-c7843becd866"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Train Loss: 3.3233, Validation Loss: 3.3200, Validation Accuracy: 0.1522\n",
            "Epoch 2, Train Loss: 3.3178, Validation Loss: 3.3251, Validation Accuracy: 0.1522\n",
            "Epoch 3, Train Loss: 3.3176, Validation Loss: 3.3212, Validation Accuracy: 0.1522\n",
            "Epoch 4, Train Loss: 3.3175, Validation Loss: 3.3207, Validation Accuracy: 0.1522\n",
            "Epoch 5, Train Loss: 3.3176, Validation Loss: 3.3239, Validation Accuracy: 0.1522\n",
            "Epoch 6, Train Loss: 3.3176, Validation Loss: 3.3205, Validation Accuracy: 0.1522\n",
            "Epoch 7, Train Loss: 3.3176, Validation Loss: 3.3228, Validation Accuracy: 0.1522\n",
            "Epoch 8, Train Loss: 3.3177, Validation Loss: 3.3218, Validation Accuracy: 0.1522\n",
            "Epoch 9, Train Loss: 3.3177, Validation Loss: 3.3220, Validation Accuracy: 0.1522\n",
            "Epoch 10, Train Loss: 3.3177, Validation Loss: 3.3196, Validation Accuracy: 0.1522\n",
            "time: 24min 38s (started: 2024-04-27 22:07:51 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install torchinfo\n",
        "import torchinfo\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTeWskQ2ju5n",
        "outputId": "c8fdd47c-606a-4b32-8e20-08e2c4b14fcf"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "time: 4.92 s (started: 2024-04-27 22:32:29 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataiter = iter(train_loader)\n",
        "inputs, labels = next(dataiter)  # Get one batch of data\n",
        "\n",
        "model.to(inputs.device)\n",
        "summary = torchinfo.summary(model, input_data=(inputs,))\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAmmFpD8jxp1",
        "outputId": "13e9e461-b7b4-48c8-dc58-37cf02124645"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===============================================================================================\n",
            "Layer (type:depth-idx)                        Output Shape              Param #\n",
            "===============================================================================================\n",
            "CharTransformer                               [128, 65]                 --\n",
            "├─Embedding: 1-1                              [128, 30, 128]            8,320\n",
            "├─TransformerEncoder: 1-2                     [128, 30, 128]            --\n",
            "│    └─ModuleList: 2-1                        --                        --\n",
            "│    │    └─TransformerEncoderLayer: 3-1      [128, 30, 128]            593,024\n",
            "│    │    └─TransformerEncoderLayer: 3-2      [128, 30, 128]            593,024\n",
            "│    │    └─TransformerEncoderLayer: 3-3      [128, 30, 128]            593,024\n",
            "├─Linear: 1-3                                 [128, 65]                 8,385\n",
            "===============================================================================================\n",
            "Total params: 1,795,777\n",
            "Trainable params: 1,795,777\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 204.50\n",
            "===============================================================================================\n",
            "Input size (MB): 0.03\n",
            "Forward/backward pass size (MB): 228.13\n",
            "Params size (MB): 6.39\n",
            "Estimated Total Size (MB): 234.55\n",
            "===============================================================================================\n",
            "time: 487 ms (started: 2024-04-27 22:32:34 +00:00)\n"
          ]
        }
      ]
    }
  ]
}